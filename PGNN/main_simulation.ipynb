{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers.legacy import Adam, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PGNN_source as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_rmspe(y_test, mu_test, offset_test = None):\n",
    "    if offset_test is None:\n",
    "        return np.sqrt(np.mean(((y_test - mu_test)**2)/mu_test))\n",
    "    else:\n",
    "        return np.sqrt(np.mean(((y_test - mu_test)**2)*offset_test/mu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d99d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = os.getcwd() + '/simulation_data/'\n",
    "data_type_list = ['1000-10-0-constant',\n",
    "                  '1000-10-0.5-gamma',   '1000-10-1-gamma', \n",
    "                  '1000-10-0.5-lognorm', '1000-10-1-lognorm', \n",
    "                  '1000-10-0.5-mixture', '1000-10-1-mixture']\n",
    "n_simul = 100\n",
    "phi_init, lam_init = 0.8, 0.8\n",
    "lr = 0.005\n",
    "patience, pretrain, moments_epochs, max_epochs = 50, 50, 50, 500\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "nodes = [10, 10, 10]\n",
    "activation = 'leaky_relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702104f9",
   "metadata": {},
   "source": [
    "## PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PX(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        expxb = Dense(1, activation='exponential')(m)\n",
    "    else: expxb = Dense(1, activation='exponential')(input_X)   \n",
    "    mean_model = Model(inputs=[input_X], outputs=[expxb])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PNN'\n",
    "model_rmspe = np.zeros((n_simul, len(data_type_list)))\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        M = make_mean_model_PX(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.Poisson())\n",
    "        M_history = M.fit([X_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test])).T\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmspe[simul_num, colnum] = compute_test_rmspe(y_test, mu_test)\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv', index=False)\n",
    "\n",
    "    print(data_type)\n",
    "    print('rmspe: ', np.round(np.mean(model_rmspe, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6b0e3",
   "metadata": {},
   "source": [
    "## PFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PF(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        expxb = Dense(1, activation='exponential')(m)\n",
    "    else: expxb = Dense(1, activation='exponential')(input_X)\n",
    "    expzv = Dense(1, activation='exponential', use_bias=False)(input_Z)        \n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[expxb*expzv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PFNN'\n",
    "model_rmspe = np.zeros((n_simul, len(data_type_list)))\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        M = make_mean_model_PF(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.Poisson())\n",
    "        M_history = M.fit([X_train, Z_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid, Z_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test, Z_test])).T\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmspe[simul_num, colnum] = compute_test_rmspe(y_test, mu_test)\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv', index=False)\n",
    "    \n",
    "    print(data_type)\n",
    "    print('rmspe: ', np.round(np.mean(model_rmspe, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27950612",
   "metadata": {},
   "source": [
    "## PGLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_HL():    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')    \n",
    "    xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb, zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1063f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PGLM'\n",
    "model_rmspe = np.zeros((n_simul, len(data_type_list)))\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        M = make_mean_model_HL()        \n",
    "        res = pg.train_model(M, train_batch, [X_train, Z_train, y_train], [X_valid, Z_valid, y_valid],\n",
    "             pg.pg_hlik_loss, optimizer, lam_init, batch_ratio, patience, pretrain, max_epochs, moments_epochs)\n",
    "        mu_test = np.exp(np.sum(M([X_test, Z_test]), axis=0).T)\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmspe[simul_num, colnum] = compute_test_rmspe(y_test, mu_test)\n",
    "        \n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv', index=False)\n",
    "\n",
    "    print(data_type)\n",
    "    print('rmspe: ', np.round(np.mean(model_rmspe, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4577d14",
   "metadata": {},
   "source": [
    "## PGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ba560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PG(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "    else: xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb, zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PGNN'\n",
    "model_rmspe = np.zeros((n_simul, len(data_type_list)))\n",
    "for data_type in data_type_list:\n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.\n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)\n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        M = make_mean_model_PG(nodes, activation)\n",
    "        res = pg.train_model(M, train_batch, [X_train, Z_train, y_train], [X_valid, Z_valid, y_valid],\n",
    "             pg.pg_hlik_loss, optimizer, lam_init, batch_ratio, patience, pretrain, max_epochs, moments_epochs)\n",
    "        mu_test = np.exp(np.sum(M([X_test, Z_test]), axis=0).T)\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmspe[simul_num, colnum] = compute_test_rmspe(y_test, mu_test)\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv', index=False)\n",
    "    \n",
    "    print(data_type)\n",
    "    print('rmspe: ', np.round(np.mean(model_rmspe, axis=0),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
