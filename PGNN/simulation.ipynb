{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e679d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PGNN_source as pg\n",
    "import NNNN_source as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_rmse(y_test, mu_test, offset_test = None):\n",
    "    if offset_test is None:\n",
    "        return np.sqrt(np.mean((y_test - mu_test)**2))\n",
    "    else:\n",
    "        return np.sqrt(np.mean(((y_test - mu_test)*offset_test)**2))\n",
    "    \n",
    "def compute_test_rmsr(y_test, mu_test, offset_test = None):\n",
    "    if offset_test is None:\n",
    "        return np.sqrt(np.mean(((y_test - mu_test)**2)/mu_test))\n",
    "    else:\n",
    "        return np.sqrt(np.mean(((y_test - mu_test)**2)*offset_test/mu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = os.getcwd()\n",
    "data_type_list = ['1000-10-0-fixed', '1000-10-0.5-gamma', '1000-10-1-gamma', '1000-10-0.5-normal', '1000-10-1-normal']\n",
    "\n",
    "n_simul = 100\n",
    "phi_init, lam_init = 0.8, 0.8\n",
    "\n",
    "lr = 0.005\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "patience, pretrain, moments_epochs, max_epochs = 50, 50, 50, 500\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "\n",
    "nodes = [10, 10, 10]\n",
    "activation = 'leaky_relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db025d8c",
   "metadata": {},
   "source": [
    "# P-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a748c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PX(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        expxb = Dense(1, activation='exponential')(m)\n",
    "    else: expxb = Dense(1, activation='exponential')(input_X)   \n",
    "    mean_model = Model(inputs=[input_X], outputs=[expxb])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_PX(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.Poisson())\n",
    "        start_time = time.time()\n",
    "        M_history = M.fit([X_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test])).T\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "\n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f944054",
   "metadata": {},
   "source": [
    "# PF-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c80034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PF(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        expxb = Dense(1, activation='exponential')(m)\n",
    "    else: expxb = Dense(1, activation='exponential')(input_X)\n",
    "    expzv = Dense(1, activation='exponential', use_bias=False)(input_Z)        \n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[expxb*expzv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbef9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_PF(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.Poisson())\n",
    "        start_time = time.time()\n",
    "        M_history = M.fit([X_train, Z_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid, Z_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test, Z_test])).T\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "    \n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996d475",
   "metadata": {},
   "source": [
    "# PG-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc444301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_PG(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "    else: xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb, zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_PG(nodes, activation)\n",
    "        start_time = time.time()\n",
    "        res = pg.train_model(M, train_batch, [X_train, Z_train, y_train], [X_valid, Z_valid, y_valid],\n",
    "             pg.pg_hlik_loss, optimizer, lam_init, batch_ratio, patience, pretrain, max_epochs, moments_epochs)\n",
    "        mu_test = np.exp(np.sum(M([X_test, Z_test]), axis=0).T)\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "    \n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc47f6",
   "metadata": {},
   "source": [
    "# N-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ffaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_NX(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "    else: xb = Dense(1, activation='linear')(input_X)   \n",
    "    mean_model = Model(inputs=[input_X], outputs=[xb])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be360441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_NX(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "        start_time = time.time()\n",
    "        M_history = M.fit([X_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test])).T\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "    \n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d60a97",
   "metadata": {},
   "source": [
    "# NF-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_NF(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "    else: xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb+zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_NF(nodes, activation)\n",
    "        M.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "        start_time = time.time()\n",
    "        M_history = M.fit([X_train, Z_train], y_train, epochs=max_epochs, batch_size=batch_size, verbose=0, \n",
    "            callbacks=callbacks, validation_data=([X_valid, Z_valid], y_valid))\n",
    "        mu_test = np.float32(M([X_test, Z_test])).T\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "    \n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda3667",
   "metadata": {},
   "source": [
    "# NN-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_NN(nodes, activation):    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')\n",
    "    if len(nodes)!=0:\n",
    "        m  = Dense(nodes[0], activation=activation)(input_X)\n",
    "        for i in range(1,len(nodes)):\n",
    "            m  = Dense(nodes[i], activation=activation)(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "    else: xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb, zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_NN(nodes, activation)\n",
    "        start_time = time.time()\n",
    "        res = nn.train_model(M, train_batch, [X_train, Z_train, y_train], [X_valid, Z_valid, y_valid],\n",
    "             nn.nn_hlik_loss, optimizer, phi_init, lam_init, batch_ratio, patience, pretrain, max_epochs, moments_epochs)\n",
    "        mu_test = np.sum(M([X_test, Z_test]), axis=0).T\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "    \n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb3859",
   "metadata": {},
   "source": [
    "# PG-GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_model_HL():    \n",
    "    input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "    input_Z = Input(shape=(np.shape(Z_train)[1],), dtype='float32')    \n",
    "    xb = Dense(1, activation='linear')(input_X)\n",
    "    zv = Dense(1, activation='linear', use_bias=False)(input_Z)\n",
    "    mean_model = Model(inputs=[input_X, input_Z], outputs=[xb, zv])\n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc577167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse, model_rmsr, model_time = [np.zeros((n_simul, len(data_type_list))) for _ in range(3)]\n",
    "for data_type in data_type_list:     \n",
    "\n",
    "    colnum = data_type_list.index(data_type)        \n",
    "    n_sub, n_num, lam, rand_dist = data_type.split('-')\n",
    "    n_sub, n_num, lam = int(n_sub), int(n_num), float(lam)\n",
    "    n_num_train, n_num_valid, n_num_test = int(n_num*0.6), int(n_num*0.2), int(n_num*0.2)\n",
    "    N_train, N_valid, N_test = n_sub * np.array([n_num_train, n_num_valid, n_num_test])\n",
    "    mu_pred = pd.DataFrame(np.zeros((N_test,n_simul)), columns=[str(x) for x in range(n_simul)], dtype=np.float32)\n",
    "\n",
    "    for simul_num in tqdm(range(n_simul)):\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "        subset_names = ['_train', '_valid', '_test']\n",
    "        for subset in subset_names:\n",
    "            exec('temp_data = data'+subset)\n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]], dtype=np.float32)')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"], dtype=np.float32)')        \n",
    "            exec('z'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('Z'+subset+'= np.eye(n_sub)[z'+subset+'].astype(\"float32\")')\n",
    "            exec('N'+subset+'= n_sub*n_num'+subset)\n",
    "        batch_size, batch_ratio = N_train, 1.            \n",
    "        pg.seed_everything()\n",
    "        train_batch = tf.data.Dataset.from_tensor_slices((X_train, Z_train, y_train)).shuffle(N_train).batch(batch_size)    \n",
    "\n",
    "        K.clear_session(); pg.seed_everything()\n",
    "        M = make_mean_model_HL()\n",
    "        start_time = time.time()\n",
    "        res = pg.train_model(M, train_batch, [X_train, Z_train, y_train], [X_valid, Z_valid, y_valid],\n",
    "             pg.pg_hlik_loss, optimizer, lam_init, batch_ratio, patience, pretrain, max_epochs, moments_epochs)\n",
    "        mu_test = np.exp(np.sum(M([X_test, Z_test]), axis=0).T)\n",
    "        timesec = time.time() - start_time\n",
    "\n",
    "        mu_pred[str(simul_num)] = mu_test.T        \n",
    "        model_rmse[simul_num, colnum] = compute_test_rmse(y_test, mu_test)\n",
    "        model_rmsr[simul_num, colnum] = compute_test_rmsr(y_test, mu_test)\n",
    "        model_time[simul_num, colnum] = timesec\n",
    "\n",
    "    mu_pred.to_csv(dir_name+data_type+'-'+model_name+'-pred.csv')\n",
    "\n",
    "    print(data_type)\n",
    "    print('time: ', np.round(np.mean(model_time, axis=0),3))\n",
    "    print('rmse: ', np.round(np.mean(model_rmse, axis=0),3))\n",
    "    print('rmsr: ', np.round(np.mean(model_rmsr, axis=0),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
