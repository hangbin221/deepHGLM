{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67e783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0f6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'C:/Users/hangbin/Google Drive/_New/Research/DeepHGLM/Simulation/data/'\n",
    "data_type_list = [\n",
    "    '20-500-2-logN',\n",
    "    '1000-10-0.5-gamma', '100-100-0.5-gamma', '20-500-0.5-gamma',\n",
    "    '1000-10-0-fixed', '100-100-0-fixed', '20-500-0-fixed',\n",
    "]\n",
    "# data_type_list = [\n",
    "#     '1000-10-2-gamma', '100-100-2-gamma', '20-500-2-gamma', \n",
    "#     '1000-10-0.5-logN','100-100-0.5-logN','20-500-0.5-logN',\n",
    "#     '1000-10-2-logN',  '100-100-2-logN',  '20-500-2-logN'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269f98ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  17:19:30  simul_num:  0\n",
      "Time:  17:22:19  simul_num:  1\n",
      "Time:  17:25:16  simul_num:  2\n",
      "Time:  17:28:15  simul_num:  3\n",
      "Time:  17:31:08  simul_num:  4\n",
      "Time:  17:34:30  simul_num:  5\n",
      "Time:  17:38:00  simul_num:  6\n",
      "Time:  17:41:13  simul_num:  7\n",
      "Time:  17:44:29  simul_num:  8\n",
      "Time:  17:47:18  simul_num:  9\n",
      "Time:  17:51:03  simul_num:  10\n",
      "Time:  17:53:18  simul_num:  11\n",
      "Time:  17:56:47  simul_num:  12\n",
      "Time:  17:59:53  simul_num:  13\n",
      "Time:  18:03:00  simul_num:  14\n",
      "Time:  18:06:18  simul_num:  15\n",
      "Time:  18:08:35  simul_num:  16\n",
      "Time:  18:12:38  simul_num:  17\n",
      "Time:  18:17:44  simul_num:  18\n",
      "Time:  18:20:50  simul_num:  19\n",
      "Time:  18:24:36  simul_num:  20\n",
      "Time:  18:27:41  simul_num:  21\n",
      "Time:  18:32:32  simul_num:  22\n",
      "Time:  18:36:26  simul_num:  23\n",
      "Time:  18:39:43  simul_num:  24\n",
      "Time:  18:42:56  simul_num:  25\n",
      "Time:  18:47:09  simul_num:  26\n",
      "Time:  18:50:22  simul_num:  27\n",
      "Time:  18:54:00  simul_num:  28\n",
      "Time:  18:56:57  simul_num:  29\n",
      "Time:  19:00:54  simul_num:  30\n",
      "Time:  19:05:28  simul_num:  31\n",
      "Time:  19:10:15  simul_num:  32\n",
      "Time:  19:13:30  simul_num:  33\n",
      "Time:  19:17:10  simul_num:  34\n",
      "Time:  19:19:58  simul_num:  35\n",
      "Time:  19:22:35  simul_num:  36\n",
      "Time:  19:26:44  simul_num:  37\n",
      "Time:  19:31:18  simul_num:  38\n",
      "Time:  19:34:19  simul_num:  39\n",
      "Time:  19:38:37  simul_num:  40\n",
      "Time:  19:41:53  simul_num:  41\n",
      "Time:  19:45:49  simul_num:  42\n",
      "Time:  19:48:57  simul_num:  43\n",
      "Time:  19:51:34  simul_num:  44\n",
      "Time:  19:57:03  simul_num:  45\n",
      "Time:  20:01:36  simul_num:  46\n",
      "Time:  20:05:05  simul_num:  47\n",
      "Time:  20:10:21  simul_num:  48\n",
      "Time:  20:14:24  simul_num:  49\n",
      "Time:  20:17:36  simul_num:  50\n",
      "Time:  20:20:32  simul_num:  51\n",
      "Time:  20:23:50  simul_num:  52\n",
      "Time:  20:28:07  simul_num:  53\n",
      "Time:  20:32:34  simul_num:  54\n",
      "Time:  20:35:47  simul_num:  55\n",
      "Time:  20:41:11  simul_num:  56\n",
      "Time:  20:43:53  simul_num:  57\n",
      "Time:  20:48:03  simul_num:  58\n",
      "Time:  20:50:30  simul_num:  59\n",
      "Time:  20:53:02  simul_num:  60\n",
      "Time:  20:57:05  simul_num:  61\n",
      "Time:  21:00:22  simul_num:  62\n",
      "Time:  21:03:56  simul_num:  63\n",
      "Time:  21:07:13  simul_num:  64\n",
      "Time:  21:10:47  simul_num:  65\n",
      "Time:  21:13:52  simul_num:  66\n",
      "Time:  21:17:21  simul_num:  67\n",
      "Time:  21:20:35  simul_num:  68\n",
      "Time:  21:24:20  simul_num:  69\n",
      "Time:  21:29:49  simul_num:  70\n",
      "Time:  21:33:53  simul_num:  71\n",
      "Time:  21:36:44  simul_num:  72\n",
      "Time:  21:41:05  simul_num:  73\n",
      "Time:  21:43:31  simul_num:  74\n",
      "Time:  21:46:08  simul_num:  75\n",
      "Time:  21:49:28  simul_num:  76\n",
      "Time:  21:53:56  simul_num:  77\n",
      "Time:  21:55:40  simul_num:  78\n",
      "Time:  21:59:42  simul_num:  79\n",
      "Time:  22:02:27  simul_num:  80\n",
      "Time:  22:05:17  simul_num:  81\n",
      "Time:  22:09:40  simul_num:  82\n",
      "Time:  22:13:17  simul_num:  83\n",
      "Time:  22:15:12  simul_num:  84\n",
      "Time:  22:18:24  simul_num:  85\n",
      "Time:  22:22:16  simul_num:  86\n",
      "Time:  22:27:19  simul_num:  87\n",
      "Time:  22:32:10  simul_num:  88\n",
      "Time:  22:36:08  simul_num:  89\n",
      "Time:  22:40:42  simul_num:  90\n",
      "Time:  22:43:37  simul_num:  91\n",
      "Time:  22:47:25  simul_num:  92\n",
      "Time:  22:50:31  simul_num:  93\n",
      "Time:  22:54:25  simul_num:  94\n",
      "Time:  22:57:41  simul_num:  95\n",
      "Time:  23:00:36  simul_num:  96\n",
      "Time:  23:03:10  simul_num:  97\n",
      "Time:  23:07:14  simul_num:  98\n",
      "Time:  23:11:23  simul_num:  99\n",
      "Time:  23:14:47  simul_num:  0\n",
      "Time:  23:17:01  simul_num:  1\n",
      "Time:  23:19:32  simul_num:  2\n",
      "Time:  23:21:53  simul_num:  3\n",
      "Time:  23:24:22  simul_num:  4\n",
      "Time:  23:26:44  simul_num:  5\n",
      "Time:  23:29:05  simul_num:  6\n",
      "Time:  23:31:32  simul_num:  7\n",
      "Time:  23:34:05  simul_num:  8\n",
      "Time:  23:36:32  simul_num:  9\n",
      "Time:  23:38:46  simul_num:  10\n",
      "Time:  23:40:55  simul_num:  11\n",
      "Time:  23:43:12  simul_num:  12\n",
      "Time:  23:45:22  simul_num:  13\n",
      "Time:  23:47:28  simul_num:  14\n",
      "Time:  23:49:48  simul_num:  15\n",
      "Time:  23:51:55  simul_num:  16\n",
      "Time:  23:54:12  simul_num:  17\n",
      "Time:  23:56:23  simul_num:  18\n",
      "Time:  23:58:30  simul_num:  19\n",
      "Time:  00:01:01  simul_num:  20\n",
      "Time:  00:03:05  simul_num:  21\n",
      "Time:  00:05:14  simul_num:  22\n",
      "Time:  00:07:25  simul_num:  23\n",
      "Time:  00:09:42  simul_num:  24\n",
      "Time:  00:11:59  simul_num:  25\n",
      "Time:  00:14:20  simul_num:  26\n",
      "Time:  00:16:23  simul_num:  27\n",
      "Time:  00:18:53  simul_num:  28\n",
      "Time:  00:21:02  simul_num:  29\n",
      "Time:  00:23:26  simul_num:  30\n",
      "Time:  00:25:45  simul_num:  31\n",
      "Time:  00:28:01  simul_num:  32\n",
      "Time:  00:30:16  simul_num:  33\n",
      "Time:  00:32:37  simul_num:  34\n",
      "Time:  00:35:08  simul_num:  35\n",
      "Time:  00:37:23  simul_num:  36\n",
      "Time:  00:39:35  simul_num:  37\n",
      "Time:  00:41:57  simul_num:  38\n",
      "Time:  00:44:23  simul_num:  39\n",
      "Time:  00:46:40  simul_num:  40\n",
      "Time:  00:48:45  simul_num:  41\n",
      "Time:  00:51:05  simul_num:  42\n",
      "Time:  00:53:25  simul_num:  43\n",
      "Time:  00:55:39  simul_num:  44\n",
      "Time:  00:57:46  simul_num:  45\n",
      "Time:  01:00:08  simul_num:  46\n",
      "Time:  01:02:23  simul_num:  47\n",
      "Time:  01:04:51  simul_num:  48\n",
      "Time:  01:07:17  simul_num:  49\n",
      "Time:  01:09:14  simul_num:  50\n",
      "Time:  01:11:36  simul_num:  51\n",
      "Time:  01:13:37  simul_num:  52\n",
      "Time:  01:16:04  simul_num:  53\n",
      "Time:  01:18:25  simul_num:  54\n",
      "Time:  01:20:35  simul_num:  55\n",
      "Time:  01:22:54  simul_num:  56\n",
      "Time:  01:25:03  simul_num:  57\n",
      "Time:  01:27:10  simul_num:  58\n",
      "Time:  01:29:18  simul_num:  59\n",
      "Time:  01:31:21  simul_num:  60\n",
      "Time:  01:33:42  simul_num:  61\n",
      "Time:  01:35:57  simul_num:  62\n",
      "Time:  01:37:57  simul_num:  63\n",
      "Time:  01:40:13  simul_num:  64\n",
      "Time:  01:42:26  simul_num:  65\n",
      "Time:  01:44:29  simul_num:  66\n",
      "Time:  01:46:39  simul_num:  67\n",
      "Time:  01:48:59  simul_num:  68\n",
      "Time:  01:51:16  simul_num:  69\n",
      "Time:  01:53:32  simul_num:  70\n",
      "Time:  01:55:51  simul_num:  71\n",
      "Time:  01:57:56  simul_num:  72\n",
      "Time:  02:00:18  simul_num:  73\n",
      "Time:  02:02:51  simul_num:  74\n",
      "Time:  02:05:06  simul_num:  75\n",
      "Time:  02:07:34  simul_num:  76\n",
      "Time:  02:09:49  simul_num:  77\n",
      "Time:  02:12:14  simul_num:  78\n",
      "Time:  02:14:28  simul_num:  79\n",
      "Time:  02:16:29  simul_num:  80\n",
      "Time:  02:18:47  simul_num:  81\n",
      "Time:  02:20:52  simul_num:  82\n",
      "Time:  02:22:56  simul_num:  83\n",
      "Time:  02:25:17  simul_num:  84\n",
      "Time:  02:27:45  simul_num:  85\n",
      "Time:  02:30:21  simul_num:  86\n",
      "Time:  02:32:52  simul_num:  87\n",
      "Time:  02:35:19  simul_num:  88\n",
      "Time:  02:37:32  simul_num:  89\n",
      "Time:  02:39:49  simul_num:  90\n",
      "Time:  02:41:40  simul_num:  91\n",
      "Time:  02:43:52  simul_num:  92\n",
      "Time:  02:46:10  simul_num:  93\n",
      "Time:  02:48:17  simul_num:  94\n",
      "Time:  02:50:31  simul_num:  95\n",
      "Time:  02:52:40  simul_num:  96\n",
      "Time:  02:54:52  simul_num:  97\n",
      "Time:  02:57:05  simul_num:  98\n",
      "Time:  02:59:19  simul_num:  99\n",
      "Time:  03:01:42  simul_num:  0\n",
      "Time:  03:03:48  simul_num:  1\n",
      "Time:  03:05:56  simul_num:  2\n",
      "Time:  03:08:00  simul_num:  3\n",
      "Time:  03:10:12  simul_num:  4\n",
      "Time:  03:13:10  simul_num:  5\n",
      "Time:  03:15:47  simul_num:  6\n",
      "Time:  03:17:51  simul_num:  7\n",
      "Time:  03:20:07  simul_num:  8\n",
      "Time:  03:23:01  simul_num:  9\n",
      "Time:  03:25:12  simul_num:  10\n",
      "Time:  03:27:05  simul_num:  11\n",
      "Time:  03:30:15  simul_num:  12\n",
      "Time:  03:32:12  simul_num:  13\n",
      "Time:  03:34:03  simul_num:  14\n",
      "Time:  03:36:06  simul_num:  15\n",
      "Time:  03:38:11  simul_num:  16\n",
      "Time:  03:40:08  simul_num:  17\n",
      "Time:  03:43:07  simul_num:  18\n",
      "Time:  03:45:19  simul_num:  19\n",
      "Time:  03:47:14  simul_num:  20\n",
      "Time:  03:49:29  simul_num:  21\n",
      "Time:  03:51:20  simul_num:  22\n",
      "Time:  03:53:21  simul_num:  23\n",
      "Time:  03:55:23  simul_num:  24\n",
      "Time:  03:57:46  simul_num:  25\n",
      "Time:  03:59:43  simul_num:  26\n",
      "Time:  04:01:34  simul_num:  27\n",
      "Time:  04:04:25  simul_num:  28\n",
      "Time:  04:06:16  simul_num:  29\n",
      "Time:  04:08:31  simul_num:  30\n",
      "Time:  04:11:16  simul_num:  31\n",
      "Time:  04:12:59  simul_num:  32\n",
      "Time:  04:14:48  simul_num:  33\n",
      "Time:  04:17:06  simul_num:  34\n",
      "Time:  04:19:00  simul_num:  35\n",
      "Time:  04:20:47  simul_num:  36\n",
      "Time:  04:22:29  simul_num:  37\n",
      "Time:  04:24:57  simul_num:  38\n",
      "Time:  04:26:50  simul_num:  39\n",
      "Time:  04:28:48  simul_num:  40\n",
      "Time:  04:30:52  simul_num:  41\n",
      "Time:  04:33:04  simul_num:  42\n",
      "Time:  04:35:01  simul_num:  43\n",
      "Time:  04:37:30  simul_num:  44\n",
      "Time:  04:39:54  simul_num:  45\n",
      "Time:  04:42:30  simul_num:  46\n",
      "Time:  04:45:11  simul_num:  47\n",
      "Time:  04:46:59  simul_num:  48\n",
      "Time:  04:48:56  simul_num:  49\n",
      "Time:  04:51:26  simul_num:  50\n",
      "Time:  04:53:18  simul_num:  51\n",
      "Time:  04:55:38  simul_num:  52\n",
      "Time:  04:58:34  simul_num:  53\n",
      "Time:  05:00:36  simul_num:  54\n",
      "Time:  05:02:54  simul_num:  55\n",
      "Time:  05:05:05  simul_num:  56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  05:07:11  simul_num:  57\n",
      "Time:  05:09:23  simul_num:  58\n",
      "Time:  05:11:24  simul_num:  59\n",
      "Time:  05:13:18  simul_num:  60\n",
      "Time:  05:15:25  simul_num:  61\n",
      "Time:  05:17:46  simul_num:  62\n",
      "Time:  05:19:38  simul_num:  63\n",
      "Time:  05:21:37  simul_num:  64\n",
      "Time:  05:24:04  simul_num:  65\n",
      "Time:  05:26:05  simul_num:  66\n",
      "Time:  05:28:20  simul_num:  67\n",
      "Time:  05:30:30  simul_num:  68\n",
      "Time:  05:32:20  simul_num:  69\n",
      "Time:  05:34:21  simul_num:  70\n",
      "Time:  05:36:32  simul_num:  71\n",
      "Time:  05:38:31  simul_num:  72\n",
      "Time:  05:41:04  simul_num:  73\n",
      "Time:  05:43:08  simul_num:  74\n",
      "Time:  05:44:55  simul_num:  75\n",
      "Time:  05:47:23  simul_num:  76\n",
      "Time:  05:49:19  simul_num:  77\n",
      "Time:  05:51:19  simul_num:  78\n",
      "Time:  05:53:09  simul_num:  79\n",
      "Time:  05:55:11  simul_num:  80\n",
      "Time:  05:57:30  simul_num:  81\n",
      "Time:  05:59:23  simul_num:  82\n",
      "Time:  06:01:45  simul_num:  83\n",
      "Time:  06:04:08  simul_num:  84\n",
      "Time:  06:07:06  simul_num:  85\n",
      "Time:  06:09:13  simul_num:  86\n",
      "Time:  06:11:05  simul_num:  87\n",
      "Time:  06:13:05  simul_num:  88\n",
      "Time:  06:14:59  simul_num:  89\n",
      "Time:  06:16:45  simul_num:  90\n",
      "Time:  06:18:37  simul_num:  91\n",
      "Time:  06:20:37  simul_num:  92\n",
      "Time:  06:22:23  simul_num:  93\n",
      "Time:  06:24:34  simul_num:  94\n",
      "Time:  06:26:44  simul_num:  95\n",
      "Time:  06:28:45  simul_num:  96\n",
      "Time:  06:30:41  simul_num:  97\n",
      "Time:  06:32:48  simul_num:  98\n",
      "Time:  06:34:53  simul_num:  99\n",
      "Time:  06:36:57  simul_num:  0\n",
      "Time:  06:39:06  simul_num:  1\n",
      "Time:  06:42:33  simul_num:  2\n",
      "Time:  06:44:59  simul_num:  3\n",
      "Time:  06:46:49  simul_num:  4\n",
      "Time:  06:48:55  simul_num:  5\n",
      "Time:  06:53:02  simul_num:  6\n",
      "Time:  06:55:07  simul_num:  7\n",
      "Time:  06:57:00  simul_num:  8\n",
      "Time:  06:58:59  simul_num:  9\n",
      "Time:  07:01:19  simul_num:  10\n",
      "Time:  07:03:02  simul_num:  11\n",
      "Time:  07:06:29  simul_num:  12\n",
      "Time:  07:08:52  simul_num:  13\n",
      "Time:  07:11:00  simul_num:  14\n",
      "Time:  07:12:42  simul_num:  15\n",
      "Time:  07:14:36  simul_num:  16\n",
      "Time:  07:16:25  simul_num:  17\n",
      "Time:  07:19:35  simul_num:  18\n",
      "Time:  07:22:00  simul_num:  19\n",
      "Time:  07:24:20  simul_num:  20\n",
      "Time:  07:26:21  simul_num:  21\n",
      "Time:  07:28:28  simul_num:  22\n",
      "Time:  07:31:25  simul_num:  23\n",
      "Time:  07:34:08  simul_num:  24\n",
      "Time:  07:36:17  simul_num:  25\n",
      "Time:  07:38:42  simul_num:  26\n",
      "Time:  07:41:46  simul_num:  27\n",
      "Time:  07:43:50  simul_num:  28\n",
      "Time:  07:45:56  simul_num:  29\n",
      "Time:  07:47:46  simul_num:  30\n",
      "Time:  07:50:14  simul_num:  31\n",
      "Time:  07:52:29  simul_num:  32\n",
      "Time:  07:54:34  simul_num:  33\n",
      "Time:  07:56:47  simul_num:  34\n",
      "Time:  07:58:50  simul_num:  35\n",
      "Time:  08:00:53  simul_num:  36\n",
      "Time:  08:02:27  simul_num:  37\n",
      "Time:  08:04:33  simul_num:  38\n",
      "Time:  08:06:13  simul_num:  39\n",
      "Time:  08:08:09  simul_num:  40\n",
      "Time:  08:09:52  simul_num:  41\n",
      "Time:  08:12:23  simul_num:  42\n",
      "Time:  08:14:54  simul_num:  43\n",
      "Time:  08:16:30  simul_num:  44\n",
      "Time:  08:19:20  simul_num:  45\n",
      "Time:  08:21:32  simul_num:  46\n",
      "Time:  08:24:14  simul_num:  47\n",
      "Time:  08:26:24  simul_num:  48\n",
      "Time:  08:28:26  simul_num:  49\n",
      "Time:  08:30:16  simul_num:  50\n",
      "Time:  08:32:17  simul_num:  51\n",
      "Time:  08:34:52  simul_num:  52\n",
      "Time:  08:37:02  simul_num:  53\n",
      "Time:  08:39:18  simul_num:  54\n",
      "Time:  08:41:32  simul_num:  55\n",
      "Time:  08:45:08  simul_num:  56\n",
      "Time:  08:47:11  simul_num:  57\n",
      "Time:  08:49:47  simul_num:  58\n",
      "Time:  08:51:25  simul_num:  59\n",
      "Time:  08:54:30  simul_num:  60\n",
      "Time:  08:56:32  simul_num:  61\n",
      "Time:  08:58:58  simul_num:  62\n",
      "Time:  09:00:46  simul_num:  63\n",
      "Time:  09:03:21  simul_num:  64\n",
      "Time:  09:05:07  simul_num:  65\n",
      "Time:  09:06:47  simul_num:  66\n",
      "Time:  09:08:41  simul_num:  67\n",
      "Time:  09:10:53  simul_num:  68\n",
      "Time:  09:12:36  simul_num:  69\n",
      "Time:  09:15:42  simul_num:  70\n",
      "Time:  09:17:36  simul_num:  71\n",
      "Time:  09:19:18  simul_num:  72\n",
      "Time:  09:22:33  simul_num:  73\n",
      "Time:  09:24:45  simul_num:  74\n",
      "Time:  09:26:31  simul_num:  75\n",
      "Time:  09:31:08  simul_num:  76\n",
      "Time:  09:33:34  simul_num:  77\n",
      "Time:  09:35:20  simul_num:  78\n",
      "Time:  09:38:05  simul_num:  79\n",
      "Time:  09:39:47  simul_num:  80\n",
      "Time:  09:42:40  simul_num:  81\n",
      "Time:  09:44:22  simul_num:  82\n",
      "Time:  09:46:19  simul_num:  83\n",
      "Time:  09:47:41  simul_num:  84\n",
      "Time:  09:49:51  simul_num:  85\n",
      "Time:  09:52:26  simul_num:  86\n",
      "Time:  09:54:33  simul_num:  87\n",
      "Time:  09:56:39  simul_num:  88\n",
      "Time:  09:58:28  simul_num:  89\n",
      "Time:  10:00:43  simul_num:  90\n",
      "Time:  10:02:40  simul_num:  91\n",
      "Time:  10:06:07  simul_num:  92\n",
      "Time:  10:07:51  simul_num:  93\n",
      "Time:  10:09:59  simul_num:  94\n",
      "Time:  10:11:21  simul_num:  95\n",
      "Time:  10:13:12  simul_num:  96\n",
      "Time:  10:14:32  simul_num:  97\n",
      "Time:  10:16:49  simul_num:  98\n",
      "Time:  10:18:30  simul_num:  99\n",
      "Time:  10:20:27  simul_num:  0\n",
      "Time:  10:22:09  simul_num:  1\n",
      "Time:  10:23:35  simul_num:  2\n",
      "Time:  10:24:54  simul_num:  3\n",
      "Time:  10:26:13  simul_num:  4\n",
      "Time:  10:27:34  simul_num:  5\n",
      "Time:  10:28:55  simul_num:  6\n",
      "Time:  10:30:06  simul_num:  7\n",
      "Time:  10:31:24  simul_num:  8\n",
      "Time:  10:32:45  simul_num:  9\n",
      "Time:  10:34:00  simul_num:  10\n",
      "Time:  10:35:05  simul_num:  11\n",
      "Time:  10:36:19  simul_num:  12\n",
      "Time:  10:37:33  simul_num:  13\n",
      "Time:  10:38:54  simul_num:  14\n",
      "Time:  10:40:09  simul_num:  15\n",
      "Time:  10:41:30  simul_num:  16\n",
      "Time:  10:42:45  simul_num:  17\n",
      "Time:  10:44:15  simul_num:  18\n",
      "Time:  10:45:34  simul_num:  19\n",
      "Time:  10:47:00  simul_num:  20\n",
      "Time:  10:48:22  simul_num:  21\n",
      "Time:  10:49:33  simul_num:  22\n",
      "Time:  10:50:44  simul_num:  23\n",
      "Time:  10:52:08  simul_num:  24\n",
      "Time:  10:53:30  simul_num:  25\n",
      "Time:  10:54:52  simul_num:  26\n",
      "Time:  10:56:11  simul_num:  27\n",
      "Time:  10:57:26  simul_num:  28\n",
      "Time:  10:58:52  simul_num:  29\n",
      "Time:  11:00:17  simul_num:  30\n",
      "Time:  11:01:33  simul_num:  31\n",
      "Time:  11:02:41  simul_num:  32\n",
      "Time:  11:04:21  simul_num:  33\n",
      "Time:  11:05:33  simul_num:  34\n",
      "Time:  11:06:47  simul_num:  35\n",
      "Time:  11:08:00  simul_num:  36\n",
      "Time:  11:09:18  simul_num:  37\n",
      "Time:  11:10:40  simul_num:  38\n",
      "Time:  11:11:49  simul_num:  39\n",
      "Time:  11:13:01  simul_num:  40\n",
      "Time:  11:14:15  simul_num:  41\n",
      "Time:  11:15:36  simul_num:  42\n",
      "Time:  11:16:58  simul_num:  43\n",
      "Time:  11:18:14  simul_num:  44\n",
      "Time:  11:19:26  simul_num:  45\n",
      "Time:  11:20:38  simul_num:  46\n",
      "Time:  11:21:57  simul_num:  47\n",
      "Time:  11:23:04  simul_num:  48\n",
      "Time:  11:24:31  simul_num:  49\n",
      "Time:  11:25:55  simul_num:  50\n",
      "Time:  11:27:08  simul_num:  51\n",
      "Time:  11:28:17  simul_num:  52\n",
      "Time:  11:29:38  simul_num:  53\n",
      "Time:  11:31:03  simul_num:  54\n",
      "Time:  11:32:12  simul_num:  55\n",
      "Time:  11:33:13  simul_num:  56\n",
      "Time:  11:34:27  simul_num:  57\n",
      "Time:  11:35:40  simul_num:  58\n",
      "Time:  11:37:16  simul_num:  59\n",
      "Time:  11:38:43  simul_num:  60\n",
      "Time:  11:39:48  simul_num:  61\n",
      "Time:  11:41:17  simul_num:  62\n",
      "Time:  11:42:35  simul_num:  63\n",
      "Time:  11:43:48  simul_num:  64\n",
      "Time:  11:45:18  simul_num:  65\n",
      "Time:  11:46:42  simul_num:  66\n",
      "Time:  11:47:54  simul_num:  67\n",
      "Time:  11:49:12  simul_num:  68\n",
      "Time:  11:50:31  simul_num:  69\n",
      "Time:  11:51:47  simul_num:  70\n",
      "Time:  11:52:57  simul_num:  71\n",
      "Time:  11:54:20  simul_num:  72\n",
      "Time:  11:55:46  simul_num:  73\n",
      "Time:  11:57:06  simul_num:  74\n",
      "Time:  11:58:26  simul_num:  75\n",
      "Time:  11:59:53  simul_num:  76\n",
      "Time:  12:01:13  simul_num:  77\n",
      "Time:  12:02:37  simul_num:  78\n",
      "Time:  12:03:50  simul_num:  79\n",
      "Time:  12:05:14  simul_num:  80\n",
      "Time:  12:06:30  simul_num:  81\n",
      "Time:  12:07:39  simul_num:  82\n",
      "Time:  12:08:56  simul_num:  83\n",
      "Time:  12:10:08  simul_num:  84\n",
      "Time:  12:11:27  simul_num:  85\n",
      "Time:  12:12:39  simul_num:  86\n",
      "Time:  12:13:59  simul_num:  87\n",
      "Time:  12:15:22  simul_num:  88\n",
      "Time:  12:16:37  simul_num:  89\n",
      "Time:  12:17:50  simul_num:  90\n",
      "Time:  12:18:56  simul_num:  91\n",
      "Time:  12:20:06  simul_num:  92\n",
      "Time:  12:21:31  simul_num:  93\n",
      "Time:  12:23:09  simul_num:  94\n",
      "Time:  12:24:28  simul_num:  95\n",
      "Time:  12:25:44  simul_num:  96\n",
      "Time:  12:26:59  simul_num:  97\n",
      "Time:  12:28:16  simul_num:  98\n",
      "Time:  12:29:31  simul_num:  99\n",
      "Time:  12:30:43  simul_num:  0\n",
      "Time:  12:32:12  simul_num:  1\n",
      "Time:  12:33:28  simul_num:  2\n",
      "Time:  12:34:47  simul_num:  3\n",
      "Time:  12:36:11  simul_num:  4\n",
      "Time:  12:37:32  simul_num:  5\n",
      "Time:  12:38:40  simul_num:  6\n",
      "Time:  12:39:41  simul_num:  7\n",
      "Time:  12:41:21  simul_num:  8\n",
      "Time:  12:42:31  simul_num:  9\n",
      "Time:  12:43:58  simul_num:  10\n",
      "Time:  12:44:42  simul_num:  11\n",
      "Time:  12:45:43  simul_num:  12\n",
      "Time:  12:46:43  simul_num:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  12:47:47  simul_num:  14\n",
      "Time:  12:48:41  simul_num:  15\n",
      "Time:  12:50:00  simul_num:  16\n",
      "Time:  12:51:30  simul_num:  17\n",
      "Time:  12:52:43  simul_num:  18\n",
      "Time:  12:54:10  simul_num:  19\n",
      "Time:  12:55:39  simul_num:  20\n",
      "Time:  12:56:49  simul_num:  21\n",
      "Time:  12:57:48  simul_num:  22\n",
      "Time:  12:58:54  simul_num:  23\n",
      "Time:  13:00:39  simul_num:  24\n",
      "Time:  13:01:35  simul_num:  25\n",
      "Time:  13:02:42  simul_num:  26\n",
      "Time:  13:03:50  simul_num:  27\n",
      "Time:  13:05:13  simul_num:  28\n",
      "Time:  13:06:52  simul_num:  29\n",
      "Time:  13:08:09  simul_num:  30\n",
      "Time:  13:09:47  simul_num:  31\n",
      "Time:  13:10:36  simul_num:  32\n",
      "Time:  13:11:56  simul_num:  33\n",
      "Time:  13:12:57  simul_num:  34\n",
      "Time:  13:14:01  simul_num:  35\n",
      "Time:  13:14:54  simul_num:  36\n",
      "Time:  13:15:44  simul_num:  37\n",
      "Time:  13:16:40  simul_num:  38\n",
      "Time:  13:17:34  simul_num:  39\n",
      "Time:  13:18:17  simul_num:  40\n",
      "Time:  13:19:35  simul_num:  41\n",
      "Time:  13:20:52  simul_num:  42\n",
      "Time:  13:22:14  simul_num:  43\n",
      "Time:  13:23:07  simul_num:  44\n",
      "Time:  13:24:14  simul_num:  45\n",
      "Time:  13:25:23  simul_num:  46\n",
      "Time:  13:26:51  simul_num:  47\n",
      "Time:  13:28:05  simul_num:  48\n",
      "Time:  13:29:04  simul_num:  49\n",
      "Time:  13:29:55  simul_num:  50\n",
      "Time:  13:31:05  simul_num:  51\n",
      "Time:  13:32:13  simul_num:  52\n",
      "Time:  13:33:43  simul_num:  53\n",
      "Time:  13:34:52  simul_num:  54\n",
      "Time:  13:35:46  simul_num:  55\n",
      "Time:  13:36:46  simul_num:  56\n",
      "Time:  13:37:52  simul_num:  57\n",
      "Time:  13:38:44  simul_num:  58\n",
      "Time:  13:39:35  simul_num:  59\n",
      "Time:  13:40:38  simul_num:  60\n",
      "Time:  13:41:51  simul_num:  61\n",
      "Time:  13:43:21  simul_num:  62\n",
      "Time:  13:44:20  simul_num:  63\n",
      "Time:  13:45:34  simul_num:  64\n",
      "Time:  13:46:57  simul_num:  65\n",
      "Time:  13:48:01  simul_num:  66\n",
      "Time:  13:48:52  simul_num:  67\n",
      "Time:  13:49:50  simul_num:  68\n",
      "Time:  13:50:53  simul_num:  69\n",
      "Time:  13:52:04  simul_num:  70\n",
      "Time:  13:53:02  simul_num:  71\n",
      "Time:  13:53:56  simul_num:  72\n",
      "Time:  13:54:49  simul_num:  73\n",
      "Time:  13:56:34  simul_num:  74\n",
      "Time:  13:57:48  simul_num:  75\n",
      "Time:  13:59:25  simul_num:  76\n",
      "Time:  14:00:45  simul_num:  77\n",
      "Time:  14:01:54  simul_num:  78\n",
      "Time:  14:02:57  simul_num:  79\n",
      "Time:  14:04:05  simul_num:  80\n",
      "Time:  14:05:15  simul_num:  81\n",
      "Time:  14:06:06  simul_num:  82\n",
      "Time:  14:07:01  simul_num:  83\n",
      "Time:  14:08:13  simul_num:  84\n",
      "Time:  14:09:22  simul_num:  85\n",
      "Time:  14:10:50  simul_num:  86\n",
      "Time:  14:12:26  simul_num:  87\n",
      "Time:  14:13:42  simul_num:  88\n",
      "Time:  14:15:01  simul_num:  89\n",
      "Time:  14:16:01  simul_num:  90\n",
      "Time:  14:17:02  simul_num:  91\n",
      "Time:  14:18:06  simul_num:  92\n",
      "Time:  14:19:02  simul_num:  93\n",
      "Time:  14:20:39  simul_num:  94\n",
      "Time:  14:22:02  simul_num:  95\n",
      "Time:  14:23:01  simul_num:  96\n",
      "Time:  14:23:44  simul_num:  97\n",
      "Time:  14:25:12  simul_num:  98\n",
      "Time:  14:26:11  simul_num:  99\n",
      "Time:  14:27:12  simul_num:  0\n",
      "Time:  14:28:14  simul_num:  1\n",
      "Time:  14:29:09  simul_num:  2\n",
      "Time:  14:30:13  simul_num:  3\n",
      "Time:  14:31:17  simul_num:  4\n",
      "Time:  14:32:28  simul_num:  5\n",
      "Time:  14:33:24  simul_num:  6\n",
      "Time:  14:34:22  simul_num:  7\n",
      "Time:  14:35:35  simul_num:  8\n",
      "Time:  14:36:42  simul_num:  9\n",
      "Time:  14:37:34  simul_num:  10\n",
      "Time:  14:38:29  simul_num:  11\n",
      "Time:  14:39:36  simul_num:  12\n",
      "Time:  14:40:24  simul_num:  13\n",
      "Time:  14:41:41  simul_num:  14\n",
      "Time:  14:42:36  simul_num:  15\n",
      "Time:  14:43:43  simul_num:  16\n",
      "Time:  14:45:14  simul_num:  17\n",
      "Time:  14:46:26  simul_num:  18\n",
      "Time:  14:47:19  simul_num:  19\n",
      "Time:  14:48:26  simul_num:  20\n",
      "Time:  14:50:06  simul_num:  21\n",
      "Time:  14:51:06  simul_num:  22\n",
      "Time:  14:52:13  simul_num:  23\n",
      "Time:  14:53:24  simul_num:  24\n",
      "Time:  14:54:16  simul_num:  25\n",
      "Time:  14:55:12  simul_num:  26\n",
      "Time:  14:56:27  simul_num:  27\n",
      "Time:  14:57:46  simul_num:  28\n",
      "Time:  14:59:30  simul_num:  29\n",
      "Time:  15:00:28  simul_num:  30\n",
      "Time:  15:02:03  simul_num:  31\n",
      "Time:  15:02:56  simul_num:  32\n",
      "Time:  15:04:38  simul_num:  33\n",
      "Time:  15:05:18  simul_num:  34\n",
      "Time:  15:06:31  simul_num:  35\n",
      "Time:  15:07:13  simul_num:  36\n",
      "Time:  15:08:09  simul_num:  37\n",
      "Time:  15:09:30  simul_num:  38\n",
      "Time:  15:10:25  simul_num:  39\n",
      "Time:  15:11:13  simul_num:  40\n",
      "Time:  15:12:25  simul_num:  41\n",
      "Time:  15:13:39  simul_num:  42\n",
      "Time:  15:14:38  simul_num:  43\n",
      "Time:  15:15:24  simul_num:  44\n",
      "Time:  15:16:50  simul_num:  45\n",
      "Time:  15:18:04  simul_num:  46\n",
      "Time:  15:19:11  simul_num:  47\n",
      "Time:  15:20:31  simul_num:  48\n",
      "Time:  15:21:35  simul_num:  49\n",
      "Time:  15:22:26  simul_num:  50\n",
      "Time:  15:23:31  simul_num:  51\n",
      "Time:  15:24:25  simul_num:  52\n",
      "Time:  15:25:33  simul_num:  53\n",
      "Time:  15:26:22  simul_num:  54\n",
      "Time:  15:27:33  simul_num:  55\n",
      "Time:  15:28:28  simul_num:  56\n",
      "Time:  15:29:28  simul_num:  57\n",
      "Time:  15:30:35  simul_num:  58\n",
      "Time:  15:31:30  simul_num:  59\n",
      "Time:  15:32:31  simul_num:  60\n",
      "Time:  15:33:28  simul_num:  61\n",
      "Time:  15:35:07  simul_num:  62\n",
      "Time:  15:36:27  simul_num:  63\n",
      "Time:  15:37:30  simul_num:  64\n",
      "Time:  15:38:37  simul_num:  65\n",
      "Time:  15:39:28  simul_num:  66\n",
      "Time:  15:40:09  simul_num:  67\n",
      "Time:  15:41:46  simul_num:  68\n",
      "Time:  15:42:38  simul_num:  69\n",
      "Time:  15:44:01  simul_num:  70\n",
      "Time:  15:44:46  simul_num:  71\n",
      "Time:  15:45:50  simul_num:  72\n",
      "Time:  15:47:03  simul_num:  73\n",
      "Time:  15:48:40  simul_num:  74\n",
      "Time:  15:49:50  simul_num:  75\n",
      "Time:  15:50:58  simul_num:  76\n",
      "Time:  15:52:14  simul_num:  77\n",
      "Time:  15:53:36  simul_num:  78\n",
      "Time:  15:54:38  simul_num:  79\n",
      "Time:  15:56:20  simul_num:  80\n",
      "Time:  15:57:29  simul_num:  81\n",
      "Time:  15:58:13  simul_num:  82\n",
      "Time:  15:59:26  simul_num:  83\n",
      "Time:  16:00:08  simul_num:  84\n",
      "Time:  16:01:10  simul_num:  85\n",
      "Time:  16:02:14  simul_num:  86\n",
      "Time:  16:03:18  simul_num:  87\n",
      "Time:  16:04:47  simul_num:  88\n",
      "Time:  16:06:15  simul_num:  89\n",
      "Time:  16:07:02  simul_num:  90\n",
      "Time:  16:07:46  simul_num:  91\n",
      "Time:  16:09:10  simul_num:  92\n",
      "Time:  16:10:06  simul_num:  93\n",
      "Time:  16:11:19  simul_num:  94\n",
      "Time:  16:12:15  simul_num:  95\n",
      "Time:  16:13:26  simul_num:  96\n",
      "Time:  16:14:27  simul_num:  97\n",
      "Time:  16:15:21  simul_num:  98\n",
      "Time:  16:16:25  simul_num:  99\n"
     ]
    }
   ],
   "source": [
    "for data_type in data_type_list:\n",
    "    \n",
    "    settings = pd.read_csv(dir_name+'simul-settings-'+data_type+'.csv')\n",
    "\n",
    "    for i in range(len(settings.columns)):\n",
    "        item = settings.columns[i]\n",
    "        if i < 5:\n",
    "            exec(item+'=np.int32(settings[\"'+item+'\"][0])')\n",
    "        else:\n",
    "            exec(item+'=settings[\"'+item+'\"][0]')\n",
    "\n",
    "    n_num_train = round(n_num*0.6)\n",
    "    n_num_valid = round(n_num*0.2)\n",
    "    n_num_test  = n_num - n_num_train - n_num_valid\n",
    "    \n",
    "    # set hyper-parameters\n",
    "\n",
    "    lam_init = 1.\n",
    "    if lam_init == lam: print(\"lam_init is same with ture lam !!!\")\n",
    "\n",
    "    num_iter = 1000\n",
    "    num_epoch = 500\n",
    "    lr = 0.001\n",
    "    threshold = 0.001\n",
    "    patience = 10\n",
    "    penalty = 10\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    # 0 = pearson, 1 = rmse(y), 2 = rmse(mu), 3 = rmse(log mu)\n",
    "    # 4 = pearson_new, 5 = rmse_new(y), 6 = rmse_new(mu), 7 = rmse(log mu)\n",
    "    # 8 = rmse(u), 9 = lambda\n",
    "\n",
    "    model_names = ['N0', 'N1', 'N2', 'M0', 'M1', 'M2', 'M3']\n",
    "\n",
    "    N0_res = np.zeros((n_simul, 10))\n",
    "    N1_res = np.zeros((n_simul, 10))\n",
    "    N2_res = np.zeros((n_simul, 10))\n",
    "    M0_res = np.zeros((n_simul, 10))\n",
    "    M1_res = np.zeros((n_simul, 10))\n",
    "    M2_res = np.zeros((n_simul, 10))\n",
    "    M3_res = np.zeros((n_simul, 10))\n",
    "        \n",
    "    for simul_num in range(n_simul):\n",
    "\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print('Time: ', current_time, ' simul_num: ', simul_num)\n",
    "\n",
    "        file_name = dir_name + 'simul-data-' + data_type + '-' + str(simul_num)\n",
    "        data = pd.read_csv(file_name+'.csv')\n",
    "        data_new = pd.read_csv(file_name+'-new.csv')\n",
    "\n",
    "        # Split data into train, valid, and test set\n",
    "\n",
    "        data_train = data[data['num'].isin(range(n_num_train))]\n",
    "        data_valid = data[data['num'].isin(range(n_num_train, n_num - n_num_test))]\n",
    "        data_test = data[-data['num'].isin(range(n_num - n_num_test))]\n",
    "\n",
    "        subset_names = ['_train', '_valid', '_test', '_new']\n",
    "        for subset in subset_names:\n",
    "\n",
    "            exec('temp_data = data'+subset)        \n",
    "            exec('X'+subset+'= np.array(temp_data[[\"x\"+str(i) for i in range(5)]])')\n",
    "            exec('y'+subset+'= np.array(temp_data[\"y\"])')        \n",
    "            exec('mu'+subset+'= np.array(temp_data[\"mu\"])')\n",
    "            exec('sub'+subset+'= np.array(temp_data[\"sub\"].astype(\"int32\"))')\n",
    "            exec('num'+subset+'= np.array(temp_data[\"num\"].astype(\"int32\"))')\n",
    "\n",
    "            if subset!='_new':\n",
    "                exec('Z_sub'+subset+'= np.eye(n_sub)[sub'+subset+']')\n",
    "                exec('N'+subset+'=n_sub*n_num'+subset)\n",
    "            else:\n",
    "                exec('Z_sub'+subset+'= np.zeros(shape=(n_new, n_sub))')\n",
    "                exec('N'+subset+'=n'+subset)\n",
    "\n",
    "            exec('dummy'+subset+'= np.zeros((N'+subset+',))')\n",
    "\n",
    "        u = np.array([data['u'][n_num*i] for i in range(n_sub)])\n",
    "        u_new = np.array(data_new['u'])    \n",
    "        batch_size = len(y_train)\n",
    "\n",
    "        ### N0 : Poi-NN ###\n",
    "\n",
    "        lam_sub_N0 = 0\n",
    "        tf.random.set_seed(simul_num)\n",
    "\n",
    "        input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "        input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "        true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "        m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "        m  = Dense(10, activation='leaky_relu')(m)        \n",
    "        m  = Dense(10, activation='leaky_relu')(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "\n",
    "        N0 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=xb)\n",
    "        loss_poi = - K.sum(true_y*(xb)-K.exp(xb))\n",
    "        N0.add_loss(loss_poi)\n",
    "        N0.compile(optimizer=optimizer)\n",
    "        history_N0 = N0.fit(\n",
    "            [X_train, Z_sub_train, y_train], dummy_train, \n",
    "            epochs=num_epoch, batch_size=batch_size, verbose=0, callbacks=callbacks,\n",
    "            validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid)\n",
    "        )\n",
    "\n",
    "        ### N1 : Poi-NN  with fixed vi (added to input) ###\n",
    "\n",
    "        lam_sub_N1 = 0\n",
    "        tf.random.set_seed(simul_num)    \n",
    "\n",
    "        input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "        input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "        true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "        XZ = Concatenate()([input_X, input_Z_sub])\n",
    "        m  = Dense(10, activation='leaky_relu')(XZ)\n",
    "        m  = Dense(10, activation='leaky_relu')(m)        \n",
    "        m  = Dense(10, activation='leaky_relu')(m)\n",
    "        xb = Dense(1, activation='linear')(m)\n",
    "\n",
    "        N1 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=xb)\n",
    "        loss_poi = - K.sum(true_y*(xb)-K.exp(xb))\n",
    "        N1.add_loss(loss_poi)\n",
    "        N1.compile(optimizer=optimizer)\n",
    "        history_N1 = N1.fit(\n",
    "            [X_train, Z_sub_train, y_train], dummy_train, \n",
    "            epochs=num_epoch, batch_size=batch_size, verbose=0, callbacks=callbacks,\n",
    "            validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid)\n",
    "        )\n",
    "\n",
    "        ### N2 : Poi-NN  with fixed vi (added to last layer) ###\n",
    "\n",
    "        lam_sub_N2 = 0\n",
    "        tf.random.set_seed(simul_num)\n",
    "\n",
    "        input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "        input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "        true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "        m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "        m  = Dense(10, activation='leaky_relu')(m)        \n",
    "        m  = Dense(10, activation='leaky_relu')(m)\n",
    "        m  = Concatenate()([m, input_Z_sub])\n",
    "        xb = Dense(1, activation='linear', use_bias=False)(m)\n",
    "\n",
    "        N2 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=xb)\n",
    "        loss_poi = - K.sum(true_y*(xb)-K.exp(xb))\n",
    "        N2.add_loss(loss_poi)\n",
    "        N2.compile(optimizer=optimizer)\n",
    "        history_N2 = N2.fit(\n",
    "            [X_train, Z_sub_train, y_train], dummy_train, \n",
    "            epochs=num_epoch, batch_size=batch_size, verbose=0, callbacks=callbacks,\n",
    "            validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid)\n",
    "        )\n",
    "\n",
    "        ### M0 : Poi-gam-NN without rand constraint, without lambda adj ###\n",
    "\n",
    "        lam_sub_M0 = lam_init\n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            ### STEP 1 : FIT NEURAL NETWORK\n",
    "\n",
    "            tf.random.set_seed(simul_num)\n",
    "\n",
    "            input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "            input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "            true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "            m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "            m  = Dense(10, activation='leaky_relu')(m)        \n",
    "            m  = Dense(10, activation='leaky_relu')(m)\n",
    "            xb = Dense(1, activation='linear')(m)\n",
    "            v_sub = Dense(1, activation='linear', use_bias=False)(input_Z_sub)    \n",
    "\n",
    "            M0 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=[xb, v_sub])\n",
    "            loss_poi_gam = (\n",
    "                - K.sum(true_y*(xb+v_sub)-K.exp(xb+v_sub))\n",
    "                - (1 / (K.ones((1, K.shape(true_y)[0]))@input_Z_sub)) @ K.transpose(input_Z_sub) @ (v_sub-K.exp(v_sub))/lam_sub_M0\n",
    "            )\n",
    "            M0.add_loss(loss_poi_gam)        \n",
    "            M0.compile(optimizer=optimizer)\n",
    "            if iteration!=0:\n",
    "                M0.set_weights(wts)\n",
    "            history_M0 = M0.fit([X_train, Z_sub_train, y_train], dummy_train, \n",
    "                                epochs=num_epoch, batch_size=batch_size, verbose=0,\n",
    "                                callbacks=callbacks,\n",
    "                                validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid))\n",
    "\n",
    "            ### STEP 2 : FIND LAMBDA\n",
    "\n",
    "            wts = M0.get_weights()\n",
    "            u_sub_pred = np.exp(wts[-1])\n",
    "            lam_sub_new = np.var(u_sub_pred, ddof=1)\n",
    "\n",
    "            if abs(lam_sub_new-lam_sub_M0) > threshold:\n",
    "                lam_sub_M0 = float(lam_sub_new)        \n",
    "            else:\n",
    "                lam_sub_M0 = float(lam_sub_new)        \n",
    "                break\n",
    "\n",
    "        ### M1 : Poi-gam-NN without rand constraint, with lambda adj ###\n",
    "\n",
    "        lam_sub_M1 = lam_init\n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            ### STEP 1 : FIT NEURAL NETWORK\n",
    "\n",
    "            tf.random.set_seed(simul_num)\n",
    "\n",
    "            input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "            input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "            true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "            m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "            m  = Dense(10, activation='leaky_relu')(m)        \n",
    "            m  = Dense(10, activation='leaky_relu')(m)\n",
    "            xb = Dense(1, activation='linear')(m)\n",
    "            v_sub = Dense(1, activation='linear', use_bias=False)(input_Z_sub)    \n",
    "\n",
    "            M1 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=[xb, v_sub])\n",
    "            loss_poi_gam = (\n",
    "                - K.sum(true_y*(xb+v_sub)-K.exp(xb+v_sub))\n",
    "                - (1 / (K.ones((1, K.shape(true_y)[0]))@input_Z_sub)) @ K.transpose(input_Z_sub) @ (v_sub-K.exp(v_sub))/lam_sub_M1\n",
    "            )\n",
    "            M1.add_loss(loss_poi_gam)    \n",
    "            M1.compile(optimizer=optimizer)\n",
    "            if iteration!=0:\n",
    "                M1.set_weights(wts)\n",
    "            history_M1 = M1.fit([X_train, Z_sub_train, y_train], dummy_train, \n",
    "                                epochs=num_epoch, batch_size=batch_size, verbose=0,\n",
    "                                callbacks=callbacks,\n",
    "                                validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid))\n",
    "\n",
    "            ### STEP 2 : FIND LAMBDA       \n",
    "\n",
    "            wts = M1.get_weights()\n",
    "            output = M1.predict([X_train, Z_sub_train, y_train])\n",
    "            mu_sum_sub = Z_sub_train.T @ np.exp(output[0]) # np.exp(output[0]) is marginal mu_hat        \n",
    "            u_sub_pred = np.exp(wts[-1])\n",
    "\n",
    "            lam_sub_new = np.sum((u_sub_pred-1)**2)/n_sub*(\n",
    "                0.5+ np.sqrt(0.25 + n_sub*np.sum((u_sub_pred-1)**2/mu_sum_sub)/(np.sum((u_sub_pred-1)**2))**2)\n",
    "            )\n",
    "            if abs(lam_sub_new-lam_sub_M1) > threshold:\n",
    "                lam_sub_M1 = float(lam_sub_new)        \n",
    "            else:\n",
    "                lam_sub_M1 = float(lam_sub_new)\n",
    "                break\n",
    "\n",
    "        ### M2 : Poi-gam-NN with rand constraint, without lambda adj ###\n",
    "\n",
    "        lam_sub_M2 = lam_init\n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            ### STEP 1 : FIT NEURAL NETWORK\\\n",
    "\n",
    "            tf.random.set_seed(simul_num)\n",
    "\n",
    "            input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "            input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "            true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "            m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "            m  = Dense(10, activation='leaky_relu')(m)        \n",
    "            m  = Dense(10, activation='leaky_relu')(m)\n",
    "            xb = Dense(1, activation='linear')(m)\n",
    "            v_sub = Dense(1, activation='linear', use_bias=False)(input_Z_sub)    \n",
    "\n",
    "            M2 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=[xb, v_sub])\n",
    "            loss_poi_gam = (\n",
    "                - K.sum(true_y*(xb+v_sub)-K.exp(xb+v_sub))\n",
    "                - (1 / (K.ones((1, K.shape(true_y)[0]))@input_Z_sub)) @ K.transpose(input_Z_sub) @ (v_sub-K.exp(v_sub))/lam_sub_M2\n",
    "            )\n",
    "            M2.add_loss(loss_poi_gam)        \n",
    "            M2.compile(optimizer=optimizer)\n",
    "            if iteration!=0:\n",
    "                M2.set_weights(wts)\n",
    "            history_M2 = M2.fit([X_train, Z_sub_train, y_train], dummy_train, \n",
    "                                epochs=num_epoch, batch_size=batch_size, verbose=0,\n",
    "                                callbacks=callbacks,\n",
    "                                validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid))\n",
    "\n",
    "            ### STEP 2 : FIND LAMBDA       \n",
    "\n",
    "            wts = M2.get_weights()\n",
    "            v_sub_adj = - np.log(np.mean(np.exp(wts[-1])))\n",
    "            wts[-2] = wts[-2] - v_sub_adj\n",
    "            wts[-1] = wts[-1] + v_sub_adj\n",
    "            M2.set_weights(wts)\n",
    "            u_sub_pred = np.exp(wts[-1])    \n",
    "\n",
    "            lam_sub_new = np.var(u_sub_pred, ddof=1)\n",
    "            if abs(lam_sub_new-lam_sub_M2) > threshold:\n",
    "                lam_sub_M2 = float(lam_sub_new)        \n",
    "            else:\n",
    "                lam_sub_M2 = float(lam_sub_new) \n",
    "                break            \n",
    "\n",
    "        ### M3 : Poi-gam-NN with rand constraint, with lambda adj ###\n",
    "\n",
    "        lam_sub_M3 = lam_init\n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            ### STEP 1 : FIT NEURAL NETWORK\n",
    "\n",
    "            tf.random.set_seed(simul_num)\n",
    "\n",
    "            input_X = Input(shape=(np.shape(X_train)[1],), dtype='float32')\n",
    "            input_Z_sub = Input(shape=(np.shape(Z_sub_train)[1],), dtype='float32')\n",
    "            true_y = Input(shape=(1,), dtype='float32')\n",
    "\n",
    "            m  = Dense(10, activation='leaky_relu')(input_X)\n",
    "            m  = Dense(10, activation='leaky_relu')(m)        \n",
    "            m  = Dense(10, activation='leaky_relu')(m)\n",
    "            xb = Dense(1, activation='linear')(m)\n",
    "            v_sub = Dense(1, activation='linear', use_bias=False)(input_Z_sub)    \n",
    "\n",
    "            M3 = Model(inputs=[input_X, input_Z_sub, true_y], outputs=[xb, v_sub])\n",
    "            loss_poi_gam = (\n",
    "                - K.sum(true_y*(xb+v_sub)-K.exp(xb+v_sub))\n",
    "                - (1 / (K.ones((1, K.shape(true_y)[0]))@input_Z_sub)) @ K.transpose(input_Z_sub) @ (v_sub-K.exp(v_sub))/lam_sub_M3\n",
    "            )\n",
    "            M3.add_loss(loss_poi_gam)\n",
    "            M3.compile(optimizer=optimizer)\n",
    "            if iteration!=0:\n",
    "                M3.set_weights(wts)\n",
    "            history_M3 = M3.fit([X_train, Z_sub_train, y_train], dummy_train, \n",
    "                                epochs=num_epoch, batch_size=batch_size, verbose=0,\n",
    "                                callbacks=callbacks,\n",
    "                                validation_data=([X_valid, Z_sub_valid, y_valid], dummy_valid))\n",
    "\n",
    "            ### STEP 2 : FIND LAMBDA       \n",
    "\n",
    "            wts = M3.get_weights()\n",
    "            v_sub_adj = - np.log(np.mean(np.exp(wts[-1])))\n",
    "            wts[-2] = wts[-2] - v_sub_adj\n",
    "            wts[-1] = wts[-1] + v_sub_adj\n",
    "            M3.set_weights(wts)\n",
    "            output = M3.predict([X_train, Z_sub_train, y_train])\n",
    "            mu_sum_sub = Z_sub_train.T @ np.exp(output[0]) # np.exp(output[0]) is marginal mu_hat\n",
    "            u_sub_pred = np.exp(wts[-1])\n",
    "\n",
    "            lam_sub_new = np.sum((u_sub_pred-1)**2)/n_sub*(\n",
    "                0.5+ np.sqrt(0.25 + n_sub*np.sum((u_sub_pred-1)**2/mu_sum_sub)/(np.sum((u_sub_pred-1)**2))**2)\n",
    "            )\n",
    "            if abs(lam_sub_new-lam_sub_M3) > threshold:\n",
    "                lam_sub_M3 = float(lam_sub_new)        \n",
    "            else:\n",
    "                lam_sub_M3 = float(lam_sub_new)\n",
    "                break\n",
    "\n",
    "        # make result frame\n",
    "\n",
    "        for model_name in model_names:\n",
    "\n",
    "            exec('output_test_'+model_name+' = '+model_name+'.predict([X_test, Z_sub_test, dummy_test])')\n",
    "            exec('output_new_'+model_name+' = '+model_name+'.predict([X_new, Z_sub_new, dummy_new])')\n",
    "            if model_name[0] == 'N':\n",
    "                exec('mu_test_'+model_name+' = np.exp(output_test_'+model_name+')')\n",
    "                exec('mu_new_'+model_name+' = np.exp(output_new_'+model_name+')')\n",
    "            else:\n",
    "                exec('mu_test_'+model_name+' = np.exp(output_test_'+model_name+'[0] + output_test_'+model_name+'[1])')\n",
    "                exec('mu_new_'+model_name+' = np.exp(output_new_'+model_name+'[0] + output_new_'+model_name+'[1])')\n",
    "            exec('mu_test_'+model_name+' = mu_test_'+model_name+'.T[0]')\n",
    "            exec('mu_new_'+model_name+' = mu_new_'+model_name+'.T[0]') \n",
    "\n",
    "            exec(model_name+'_res[simul_num, 0] = np.sqrt(np.mean((y_test - mu_test_'+model_name+')**2/mu_test_'+model_name+'))')\n",
    "            exec(model_name+'_res[simul_num, 1] = np.sqrt(np.mean((y_test - mu_test_'+model_name+')**2))')\n",
    "            exec(model_name+'_res[simul_num, 2] = np.sqrt(np.mean((mu_test - mu_test_'+model_name+')**2))')\n",
    "            exec(model_name+'_res[simul_num, 3] = np.sqrt(np.mean((np.log(mu_test) - np.log(mu_test_'+model_name+'))**2))')\n",
    "            exec(model_name+'_res[simul_num, 4] = np.sqrt(np.mean((y_new - mu_new_'+model_name+')**2/mu_new_'+model_name+'))')\n",
    "            exec(model_name+'_res[simul_num, 5] = np.sqrt(np.mean((y_new - mu_new_'+model_name+')**2))')\n",
    "            exec(model_name+'_res[simul_num, 6] = np.sqrt(np.mean((mu_new - mu_new_'+model_name+')**2))')\n",
    "            exec(model_name+'_res[simul_num, 7] = np.sqrt(np.mean((np.log(mu_new) - np.log(mu_new_'+model_name+'))**2))')\n",
    "\n",
    "            if model_name[0] == 'M':\n",
    "                exec('u_pred_'+model_name+' = np.exp('+model_name+'.get_weights()[-1].T[0])')\n",
    "                exec(model_name+'_res[simul_num, 8] = np.sqrt(np.mean((u - u_pred_'+model_name+')**2))')\n",
    "                exec(model_name+'_res[simul_num, 9] = lam_sub_'+model_name)\n",
    "            elif model_name == 'N2':\n",
    "                exec('u_pred_'+model_name+' = np.exp('+model_name+'.get_weights()[-1].T[0][10:])')\n",
    "                exec(model_name+'_res[simul_num, 8] = np.sqrt(np.mean((u - u_pred_'+model_name+')**2))')\n",
    "                exec(model_name+'_res[simul_num, 9] = lam_sub_'+model_name)\n",
    "                \n",
    "    res_colnames = ['RMSE_p', 'RMSE_y', 'RMSE_mu', 'RMSE_log_mu', \n",
    "                    'RMSE_p_new', 'RMSE_y_new', 'RMSE_mu_new', 'RMSE_log_mu_new', \n",
    "                    'RMSE_u', 'lambda']\n",
    "\n",
    "    sample_mu_test = np.zeros((N_test, len(model_names)))\n",
    "    sample_mu_new = np.zeros((N_new, len(model_names)))\n",
    "\n",
    "    for i in range(len(model_names)):\n",
    "        model_name = model_names[i]\n",
    "        exec(model_name+'_res = pd.DataFrame('+model_name+'_res, columns=res_colnames)')    \n",
    "        exec(model_name+'_res.to_csv(dir_name+data_type+\"-\"+model_name+\".csv\", index=False)')\n",
    "        exec('sample_mu_test[:,'+str(i)+'] = mu_test_'+model_name)\n",
    "        exec('sample_mu_new[:,'+str(i)+'] = mu_new_'+model_name)\n",
    "\n",
    "    sample_mu_test = pd.DataFrame(sample_mu_test, columns=model_names)\n",
    "    sample_mu_test.to_csv(dir_name+'sample-mu-'+data_type+'.csv')\n",
    "    sample_mu_new = pd.DataFrame(sample_mu_new, columns=model_names)\n",
    "    sample_mu_new.to_csv(dir_name+'sample-mu-'+data_type+'-new.csv')\n",
    "                \n",
    "\n",
    "winsound.Beep(440, 1000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755728b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
